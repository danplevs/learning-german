{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDJCNAAyLYgo"
   },
   "source": [
    "# To do \n",
    "- [x] Add translation of the input phrase and of the words table\n",
    "- [x] Add text to speech method\n",
    "- [ ] Add words learned attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sYx8t3xtuCI"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "fiToZVhyEkka"
   },
   "outputs": [],
   "source": [
    "# nlp library\n",
    "import spacy\n",
    "# de, en nlp models\n",
    "import de_core_news_sm, en_core_web_sm\n",
    "# data wrangling\n",
    "import pandas as pd\n",
    "# translation\n",
    "from google.cloud import translate_v2\n",
    "# create google application credentials env variable\n",
    "import os\n",
    "# text to speech\n",
    "from gtts import gTTS\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningGerman:\n",
    "    def __init__(self, text='testen'):\n",
    "        self.text = text\n",
    "        self.words, self.lemma, self.pos, self.details = ([] for c in range(4))\n",
    "        self.table_ = pd.DataFrame()\n",
    "        self.client = translate_v2.Client()\n",
    "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '.projdata/credentials.json'\n",
    "        self.language = self.client.detect_language(self.text)['language']\n",
    "        if self.language == 'de':\n",
    "            self.to = 'en'\n",
    "        elif self.language == 'en':\n",
    "            self.to = 'de'\n",
    "        self.model = 'nmt'\n",
    "    \n",
    "    @property\n",
    "    def table(self):\n",
    "        if self.table_.empty:\n",
    "            print('To create a complete vocab chart, please call nlp()!')\n",
    "        else:\n",
    "            return self.table_\n",
    "    \n",
    "    @staticmethod\n",
    "    def drop_punct(table):\n",
    "        if table['pos'].str.contains('PUNCT').any():\n",
    "            table.drop(table[table.pos == 'PUNCT'].index, inplace=True)\n",
    "    \n",
    "    def translate(self, words=False):\n",
    "        if words == False:\n",
    "            return self.client.translate(self.text, source_language=self.language, target_language=self.to, \n",
    "                             model=self.model, format_='text')['translatedText']\n",
    "        else:\n",
    "            return [self.client.translate(word, source_language=self.language, target_language=self.to, \n",
    "                             model=self.model, format_='text')['translatedText'] for word in self.words]\n",
    "    \n",
    "    def nlp(self, visualize=False):\n",
    "        if self.language == 'de':\n",
    "            nlp = de_core_news_sm.load()\n",
    "            column_names = ['deutsche']\n",
    "        elif self.language == 'en':\n",
    "            nlp = en_core_web_sm.load()\n",
    "            column_names = ['english']\n",
    "        doc = nlp(self.text)\n",
    "        columns = ['lemma', 'pos', 'details']\n",
    "        column_names.extend(columns)\n",
    "        for token in doc:\n",
    "            self.words.append(token.text)\n",
    "            self.lemma.append(token.lemma_.lower())\n",
    "            self.pos.append(token.pos_)\n",
    "            self.details.append(spacy.explain(token.tag_))\n",
    "        words_table = pd.DataFrame(data=zip(self.words, self.lemma, self.pos, self.details), columns=column_names)\n",
    "        words_table['translation'] = self.translate(words=True)\n",
    "        self.drop_punct(words_table)\n",
    "        if visualize == True:\n",
    "            spacy.displacy.render(doc, style='dep')\n",
    "        print(f'\\033[1;33m{self.text}\\033[m -> {self.translate()}')\n",
    "        self.table_ = words_table\n",
    "        return words_table\n",
    "    \n",
    "    def say(self, translation=False, slowmode=False, autoplay=True):\n",
    "        if translation == False:\n",
    "            print(f'\\033[1;33m{self.language}')\n",
    "            speech = gTTS(self.text, lang=self.language, slow=slowmode)\n",
    "            speech.save('.projdata/speech.mp3')\n",
    "        else:\n",
    "            print(f'\\033[1m{self.to}')\n",
    "            speech = gTTS(self.translate(), lang=self.to, slow=slowmode)\n",
    "            speech.save('.projdata/speech.mp3')\n",
    "        return Audio('.projdata/speech.mp3', autoplay=autoplay)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_sYx8t3xtuCI",
    "9H56XsSzt39w",
    "Bdb91bKZL7AY",
    "W42S0_QMMFQo",
    "AoQP1XJ1KdMk"
   ],
   "name": "LearningGerman.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
