{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDJCNAAyLYgo"
   },
   "source": [
    "# To do \n",
    "- [ ] Add translation of the input phrase and of the words table\n",
    "- [ ] Add text to speech method\n",
    "- [ ] Add words learned attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sYx8t3xtuCI"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fiToZVhyEkka"
   },
   "outputs": [],
   "source": [
    "# web scraping \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# nlp library\n",
    "import spacy\n",
    "# de, en nlp models\n",
    "import de_core_news_sm, en_core_web_sm\n",
    "# data wrangling\n",
    "import pandas as pd\n",
    "# translation\n",
    "from google.cloud import translate_v2\n",
    "# create google application credentials\n",
    "import os\n",
    "# text to speech\n",
    "from gtts import gTTS\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningGerman:\n",
    "    def __init__(self, text='testen'):\n",
    "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '.projdata/credentials.json'\n",
    "        self.client = translate_v2.Client()\n",
    "        self.text = text\n",
    "        self.language = self.client.detect_language(self.text)['language']\n",
    "        self.model = 'nmt'\n",
    "        self.table = self.nlp()\n",
    "    \n",
    "    def translate(self):\n",
    "        if self.language == 'de':\n",
    "            to = 'en'\n",
    "        elif self.language == 'en':\n",
    "            to = 'de'\n",
    "        return self.client.translate(self.text, source_language=self.language, target_language=to, \n",
    "                         model=self.model)['translatedText']\n",
    "    \n",
    "    def nlp(self):\n",
    "        if self.language == 'de':\n",
    "            nlp = de_core_news_sm.load()\n",
    "            column_names = ['deutsche']\n",
    "        elif self.language == 'en':\n",
    "            nlp = en_core_web_sm.load()\n",
    "            column_names = ['english']\n",
    "        doc = nlp(self.text)\n",
    "        words, lemma, pos, details = ([] for i in range(4))\n",
    "        columns = ['lemma', 'pos', 'details']\n",
    "        column_names.extend(columns)\n",
    "        for token in doc:\n",
    "            words.append(token.text)\n",
    "            lemma.append(token.lemma_.lower())\n",
    "            pos.append(token.pos_)\n",
    "            details.append(spacy.explain(token.tag_))\n",
    "        words_table = pd.DataFrame(data=zip(words, lemma, pos, details), columns=column_names)\n",
    "        self.drop_punct(words_table)\n",
    "        return words_table\n",
    "    \n",
    "    @staticmethod\n",
    "    def drop_punct(table):\n",
    "        if table['pos'].str.contains('PUNCT').any():\n",
    "            table.drop(table[table.pos == 'PUNCT'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H56XsSzt39w"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIwkNJy04HdM"
   },
   "source": [
    "## Text to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "S3TaLXRfuv92"
   },
   "outputs": [],
   "source": [
    "def de_say(txt, language='de', slowmode=False):\n",
    "    speech = gTTS(txt, lang=language, slow=slowmode)\n",
    "    speech.save('speech.mp3')\n",
    "    return Audio('speech.mp3', autoplay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '.projdata/credentials.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(txt, target='en', src='en'):\n",
    "    translate_client = translate_v2.Client()\n",
    "    result = translate_client.translate(txt, target_language=target, source_language=src, model='nmt')['translatedText']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_to_en(txt):\n",
    "    print(translate(txt, target='en', src='de'))\n",
    "    process_de(txt)\n",
    "    return words_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_to_de(txt):\n",
    "    print(translate(txt, target='de', src='en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_de(txt):\n",
    "    nlp = de_core_news_sm.load()\n",
    "    doc = nlp(txt)\n",
    "    deutsche, lemma, details = ([] for i in range(3))\n",
    "    column_names = ['deutsche', 'lemma', 'details']\n",
    "    for token in doc:\n",
    "        deutsche.append(token.text)\n",
    "        lemma.append(token.lemma_.lower())\n",
    "        details.append(spacy.explain(token.tag_))\n",
    "    words_table = pd.DataFrame(data=zip(deutsche, lemma, details), columns=column_names)\n",
    "    return words_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deutsche</th>\n",
       "      <th>lemma</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich</td>\n",
       "      <td>ich</td>\n",
       "      <td>non-reflexive personal pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bin</td>\n",
       "      <td>sein</td>\n",
       "      <td>finite verb, auxiliary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ein</td>\n",
       "      <td>einen</td>\n",
       "      <td>definite or indefinite article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junge</td>\n",
       "      <td>junge</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  deutsche  lemma                         details\n",
       "0      Ich    ich  non-reflexive personal pronoun\n",
       "1      bin   sein          finite verb, auxiliary\n",
       "2      ein  einen  definite or indefinite article\n",
       "3    Junge  junge          noun, singular or mass"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_de('Ich bin ein Junge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bdb91bKZL7AY"
   },
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7SYuJWsNXNm",
    "outputId": "8440c307-321c-47b1-9eb1-0dacbb21cbb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# creating a HTTP request to extract the HTML code that contains the phrases\n",
    "url = 'https://www.rosettastone.com/languages/german-phrases/'\n",
    "page = requests.get(url)\n",
    "# checking the status of the request\n",
    "if page.status_code == 200:\n",
    "  print('OK!')\n",
    "else:\n",
    "  print('404 ERROR!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFopmamwOsBY",
    "outputId": "639dfa24-de0f-4b73-defe-97ebc29db398"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ul>\n",
       "<li>Guten Tag = Good morning</li>\n",
       "<li>Hallo = Hello</li>\n",
       "<li>Ich heiße … = My name is …</li>\n",
       "<li>Sprechen Sie Englisch? = Do you speak English?</li>\n",
       "<li>Wie heißt du? = What’s your name?</li>\n",
       "<li>Wie geht es dir? = How are you?</li>\n",
       "<li>Gut, danke = Fine, thank you</li>\n",
       "<li>Nett, Sie kennen zu lernen = Nice to meet you</li>\n",
       "<li>Tisch für zwei bitte = Table for two, please</li>\n",
       "<li>Wo ist die Toilette? = Where is the bathroom?</li>\n",
       "<li>Danke = Thank you</li>\n",
       "<li>Wie komme ich zu …? = How can I get to …?</li>\n",
       "<li>Gibt es ein Restaurant in der Nähe? = Is there a restaurant nearby?</li>\n",
       "<li>Ich liebe dich = I love you</li>\n",
       "<li>Wie viel kostet das …? = How much is this …?</li>\n",
       "<li>Es tut mir leid, ich verstehe das nicht = Sorry, I don’t understand</li>\n",
       "<li>Haben Sie noch Zimmer frei? = Do you have any rooms available?</li>\n",
       "<li>Auf Wiedersehen = Goodbye</li>\n",
       "</ul>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting HTML list tag from the page\n",
    "page_content = BeautifulSoup(page.content, 'html.parser')\n",
    "phrase_html_list = page_content.ul\n",
    "phrase_html_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rheR-wXcIate",
    "outputId": "e228f827-d1b5-4bb5-efb6-61fe0a64c9e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Guten Tag',\n",
       " 'Hallo',\n",
       " 'Ich heiße …',\n",
       " 'Sprechen Sie Englisch?',\n",
       " 'Wie heißt du?',\n",
       " 'Wie geht es dir?',\n",
       " 'Gut, danke',\n",
       " 'Nett, Sie kennen zu lernen',\n",
       " 'Tisch für zwei bitte',\n",
       " 'Wo ist die Toilette?',\n",
       " 'Danke',\n",
       " 'Wie komme ich zu …?',\n",
       " 'Gibt es ein Restaurant in der Nähe?',\n",
       " 'Ich liebe dich',\n",
       " 'Wie viel kostet das …?',\n",
       " 'Es tut mir leid, ich verstehe das nicht',\n",
       " 'Haben Sie noch Zimmer frei?',\n",
       " 'Auf Wiedersehen']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting only the deutsche parts of the strings\n",
    "deutsche_list = []\n",
    "for phrase in phrase_html_list.stripped_strings:\n",
    "  deutsche_list.append(phrase.split(' = ')[0])\n",
    "deutsche_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W42S0_QMMFQo"
   },
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9pN1U3IFMH6z"
   },
   "outputs": [],
   "source": [
    "# loading the deutsche model \n",
    "nlp = de_core_news_sm.load()\n",
    "# processing our sample\n",
    "doc_list = [nlp(phrase) for phrase in deutsche_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMJuULdsKk7p"
   },
   "source": [
    "**de_text**: The original deutsche word text.  \n",
    "**lemma**: The base form of the word.   \n",
    "**pos**: The simple UPOS part-of-speech tag (list of universal POS tags: https://universaldependencies.org/docs/u/pos/)  \n",
    "**details**: The detailed part-of-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tcyvNcHnQFGD",
    "outputId": "ae515940-6d50-4aa4-d47a-f71e9af1b8bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deutsche</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guten</td>\n",
       "      <td>guten</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective, attributive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tag</td>\n",
       "      <td>tag</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  deutsche  lemma   pos                 details\n",
       "0    Guten  guten   ADJ  adjective, attributive\n",
       "1      Tag    tag  NOUN  noun, singular or mass"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring the dataframe columns and containers for the values\n",
    "column_names = ['deutsche', 'lemma', 'pos', 'details']\n",
    "deutsche_text, lemma, pos, details = ([] for i in range(4))\n",
    "\n",
    "\n",
    "# collecting 13th phrase data\n",
    "for word in doc_list[0]:\n",
    "  deutsche_text.append(word.text)\n",
    "  lemma.append(word.lemma_.lower()) \n",
    "  pos.append(word.pos_) \n",
    "  details.append(spacy.explain(word.tag_))\n",
    "\n",
    "\n",
    "# creating the words dataframe\n",
    "words = pd.DataFrame(data=zip(deutsche_text, lemma, pos, details), columns=column_names)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "Bs9WGKKbv1in",
    "outputId": "0bb91bbc-daad-4c2e-98b5-f96efec1dbfe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deutsche</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guten</td>\n",
       "      <td>guten</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective, attributive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tag</td>\n",
       "      <td>tag</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  deutsche  lemma   pos                 details\n",
       "0    Guten  guten   ADJ  adjective, attributive\n",
       "1      Tag    tag  NOUN  noun, singular or mass"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for punctuation and removing it if true\n",
    "if words['pos'].str.contains('PUNCT').any():\n",
    "  words.drop(words[words.pos == 'PUNCT'].index, inplace=True)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoQP1XJ1KdMk"
   },
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deutsche</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>details</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guten</td>\n",
       "      <td>guten</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective, attributive</td>\n",
       "      <td>Good ones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tag</td>\n",
       "      <td>tag</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  deutsche  lemma   pos                 details    english\n",
       "0    Guten  guten   ADJ  adjective, attributive  Good ones\n",
       "1      Tag    tag  NOUN  noun, singular or mass        Day"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'credentials.json'\n",
    "\n",
    "translate_client = translate.Client()\n",
    "\n",
    "translated_words = [translate_client.translate(word, target_language='en', source_language='de', model='nmt')['translatedText'] for word in words['deutsche']]\n",
    "words['english'] = translated_words\n",
    "words"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_sYx8t3xtuCI",
    "9H56XsSzt39w",
    "Bdb91bKZL7AY",
    "W42S0_QMMFQo",
    "AoQP1XJ1KdMk"
   ],
   "name": "LearningGerman.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
